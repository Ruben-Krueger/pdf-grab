'''''
A script to scrape the PDFs generated by FlyWheel.
Author: Ruben Krueger
'''''

import re
import PyPDF2
import os
import sys
from openpyxl import Workbook
import argparse


def get_text(path):
    ''''' Return the text from a PDF.
        Args:
            path (string): File path to PDF.
        Returns:
            string: Text content of PDF
    '''
    f = open(path, 'rb')
    pdf_file = PyPDF2.PdfFileReader(f)
    text = pdf_file.getPage(0).extractText().replace('\n', ' ')
    return text


def get_session(filename):
    if re.search('pain', filename) is not None:
        return 'PAIN'
    if re.search('stroop', filename) is not None:
        return 'STROOP'

    return 'N/A'


def get_fit(text, filename):
    # get raw strings
    gaba_glx_water = re.search(
        "GABA\+\/Glx \(Water\).*i\.u\.", text).group(0).replace('i.u.', '')
    gaba_glx_cr = re.search("GABA\+\/Glx \(Cr\).*FitVer",
                            text).group(0).replace('FitVer', '')
    fit_err = re.search("FitErr.*%", text).group(0)

    fit_gaba = re.search("GABA:.* \/ ", fit_err).group(0)
    fit_glx = re.search("Glx:.*%", fit_err).group(0)

    gaba_glx_water = gaba_glx_water.replace('GABA+/Glx (Water): ', "")
    gaba_glx_cr = gaba_glx_cr.replace('GABA+/Glx (Cr): ', "")

    if gaba_glx_water == '' or gaba_glx_cr == '':
        print('could not find raw text!')

    gaba_glx_water = re.sub('[^0-9.\/]', '', gaba_glx_water)
    gaba_glx_cr = re.sub('[^0-9.\/]', '', gaba_glx_cr)

    if gaba_glx_water[0] == "/":
        gaba_glx_water = gaba_glx_water[1:]

    if gaba_glx_cr[0] == "/":
        gaba_glx_cr = gaba_glx_cr[1:]

    # get numeric values
    gaba_water = re.search('^[0-9.]*', gaba_glx_water).group(0)
    glx_water = re.search(
        '\/[0-9.]*', gaba_glx_water).group(0).replace('/', '')
    gaba_cr = re.search('^[0-9.]*', gaba_glx_cr).group(0)
    glx_cr = re.search('\/[0-9.]*', gaba_glx_cr).group(0).replace('/', '')

    fit_gaba_water = re.search('[0-9.]*\/', fit_gaba).group(0).replace('/', '')
    fit_gaba_cr = re.search('\/[0-9.]*', fit_gaba).group(0).replace('/', '')
    fit_glx_water = re.search('[0-9.]*\/', fit_glx).group(0).replace('/', '')
    fit_glx_cr = re.search('\/[0-9.]*', fit_glx).group(0).replace('/', '')

    session = get_session(filename)

    scan_type = "HC" if re.search("HC", filename) is not None else "R33"
    subject_id = re.search('[0-9]{3}', filename).group(0)
    subject = scan_type + "_" + subject_id

    return {'Subject': subject, 'Scan Type': scan_type, 'Session': session,
            'GABA/Water': gaba_water, 'Glx/Water': glx_water,
            'GABA/Cr': gaba_cr, 'Glx/Cr': glx_cr, 'fit_gaba_water': fit_gaba_water, 'fit_gaba_cr': fit_gaba_cr,
            'fit_glx_water': fit_glx_water, 'fit_glx_cr': fit_glx_cr,
            'file': filename
            }


def get_quantity(text, filename):
    gaba_glx = re.findall("GABA\+\/Glx[0-9:\/ .]* i.u.", text)
    vals = []

    if len(gaba_glx) == 0:
        gaba_glx = re.findall("GABA\+\/Glx.*[0-9:\/ .]* i.u.", text)

        vals = re.findall("[\-]?[0-9].[0-9]+", gaba_glx[0])

    else:
        for s in gaba_glx:
            data = re.search("[-]?[0-9.]+\/[0-9.]*", s).group(0)
            vals += data.split('/')

    s_type = "HC" if re.search("HC", filename) is not None else "R33"
    subject_id = re.search('[0-9]{3}', filename).group(0)
    subject = s_type + "_" + subject_id

    return {'Filename': filename, "Subject": subject, "GABA+":
            vals[0], "Glx": vals[1], "GABA-alpha": vals[2], "Glx-alpha": vals[3],
            "GABA-average": vals[4], "Glx-average": vals[5]}


def get_segment(text, filename):
    gm = re.search(
        "GM voxel fraction:   [0-9.]*", text).group(0).replace("GM voxel fraction:", "")
    wm = re.search(
        "WM voxel fraction:   [0-9.]*", text).group(0).replace("WM voxel fraction:", "")
    csf = re.search(
        "CSF voxel fraction:   [0-9.]*", text).group(0).replace("CSF voxel fraction:", "")

    s_type = "HC" if re.search("HC", filename) is not None else "R33"
    subject_id = re.search('[0-9]{3}', filename).group(0)
    subject = s_type + "_" + subject_id

    scan_type = "pre" if re.search("pre", filename) is not None else "post"
    measure = "stroop" if re.search("stroop", filename) is not None else "pain"

    return {'Filename': filename, "Subject": subject, "Scan Type": scan_type, "Measure": measure, "GM": gm, "WM": wm,  "CSF": csf}


def check_values(vals, filename):
    for k in vals.keys():
        if vals[k] == '':
            print('FAILED: {}'.format(filename))
            print('Could not parse: {}'.format(k))
            return False

    return True


def write_vals(vals, output):
    ''''' Write the values in the vals dictionary to output path.
        Args:
            vals (string): File path to PDF.
            output (string): File path to spreadsheet which it is saved to.
        Returns:
            None
    '''''

    wb = Workbook()
    ws = wb.active

    labels = vals[0].keys()
    col = 1
    for label in labels:
        ws.cell(row=1, column=col, value=label)
        col += 1

    row = 2
    for val_dict in vals:
        col = 1
        for k, v in val_dict.items():
            ws.cell(row=row, column=col, value=v)
            col += 1
        row += 1

    wb.save(output)


def scrape_pdfs(data_dir, output_file, get_values_func):

    worked = 0
    total = 0

    values = []

    for name in os.listdir(data_dir):
        path = data_dir + name
        if os.path.isdir(path) or not path.endswith('.pdf'):
            continue
        text = get_text(path)
        nums = get_values_func(text, name)
        values.append(nums)
        if check_values(nums, name):
            worked += 1
        total += 1

    write_vals(values, output_file)

    print('Correctly parsed: {}, Total: {}'.format(worked, total))


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("--fit", help="fit folder path", action="store_true")

    parser.add_argument(
        "--quantity", help="quantity folder path", action="store_true")

    parser.add_argument(
        "--segment", help="segment folder path", action="store_true")

    args = parser.parse_args()

    fit_dir = "./data/GannetFit_output/"
    segment_dir = "./data/GannetSegment_output/GannetSegment_output/"
    quantity_dir = "./data/GannetQuantify_output/GannetQuantify_output/"

    if(len(sys.argv) < 2):
        print("Need to supply one or more of -fit, -quantity, -segment")
        exit()

    if args.fit:
        outfile = "fit.csv"
        print(f"Writing to {outfile}")
        scrape_pdfs(fit_dir, outfile, get_fit)

    if args.segment:
        outfile = "segment.csv"
        print(f"Writing to {outfile}")
        scrape_pdfs(segment_dir, outfile, get_segment)

    if args.quantity:
        outfile = "quantity.csv"
        print(f"Writing to {outfile}")
        scrape_pdfs(quantity_dir, outfile, get_quantity)


if __name__ == '__main__':
    main()
